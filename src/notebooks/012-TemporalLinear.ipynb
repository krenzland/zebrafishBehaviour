{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style('whitegrid')\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from sklearn.linear_model import RidgeCV, MultiTaskElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv( '../../data/processed/rf_train.csv')\n",
    "df_test = pd.read_csv( '../../data/processed/rf_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dt', 'feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
       "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
       "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
       "       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n",
       "       'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24',\n",
       "       'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29',\n",
       "       'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34',\n",
       "       'feature_35', 'feature_36', 'feature_37', 'y_0', 'y_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_dts = len(np.unique(df_train['dt']))\n",
    "y_labels = ['y_0', 'y_1']\n",
    "y_train = df_train.loc[df_train['dt'] == 0, y_labels].values\n",
    "y_test = df_test.loc[df_train['dt'] == 0, y_labels].values\n",
    "\n",
    "# First concatenate all timesteps together one weight per combination of time and feature\n",
    "X_train = df_train.drop(labels=y_labels + ['dt'], axis=1).values.reshape(df_train.shape[0]//num_dts, -1)\n",
    "X_test = df_test.drop(labels=y_labels + ['dt'], axis=1).values.reshape(df_test.shape[0]//num_dts, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.00000e-10, 3.04699e-10, 9.28415e-10, 2.82887e-09, 8.61954e-09,\n",
       "       2.62636e-08, 8.00250e-08, 2.43835e-07, 7.42964e-07, 2.26380e-06,\n",
       "       6.89779e-06, 2.10175e-05, 6.40400e-05, 1.95129e-04, 5.94557e-04,\n",
       "       1.81161e-03, 5.51995e-03, 1.68192e-02, 5.12481e-02, 1.56152e-01,\n",
       "       4.75794e-01, 1.44974e+00, 4.41734e+00, 1.34596e+01, 4.10113e+01,\n",
       "       1.24961e+02, 3.80755e+02, 1.16016e+03, 3.53498e+03, 1.07711e+04,\n",
       "       3.28193e+04, 1.00000e+05]),\n",
       "    cv=None, fit_intercept=True, gcv_mode=None, normalize=False,\n",
       "    scoring=None, store_cv_values=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = RidgeCV(alphas=np.logspace(-10, 5, num=32))\n",
    "linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.183042380132744, 0.10844945530163266)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.score(X_train, y_train), linear.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11252544,  0.11454252],\n",
       "       [ 1.34859902, -0.19781908],\n",
       "       [ 1.42869322, -0.3084776 ],\n",
       "       ...,\n",
       "       [ 1.65033971,  0.2982384 ],\n",
       "       [ 1.60091703,  0.42215438],\n",
       "       [ 1.11190763,  0.73622077]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_hat = linear.predict(X_test)\n",
    "y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20786, 38])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = ['y_0', 'y_1']\n",
    "y_train_np = df_train.loc[df_train['dt'] == 0, y_labels].values\n",
    "y_test_np = df_test.loc[df_train['dt'] == 0, y_labels].values\n",
    "\n",
    "num_dts = len(np.unique(df_train['dt']))\n",
    "num_features = df_train.shape[1] - 3# # minus rows dt, y_0, y_1\n",
    "\n",
    "X_train_np = df_train.drop(labels=y_labels + ['dt'], axis=1).values\n",
    "X_test_np = df_test.drop(labels=y_labels + ['dt'], axis=1).values\n",
    "\n",
    "# Reshape from (dts*kicks, features) to (features, dts, kicks)\n",
    "X_train_np = X_train_np.reshape(X_train_np.shape[0]//num_dts, num_dts,num_features)\n",
    "X_test_np = X_test_np.reshape(X_test_np.shape[0]//num_dts, num_dts, num_features)\n",
    "\n",
    "# Transpose to (dts, kicks, features)\n",
    "X_train_np = X_train_np.transpose(1,0, 2)\n",
    "X_test_np = X_test_np.transpose(1,0, 2)\n",
    "\n",
    "# To Tensors\n",
    "X_train = torch.from_numpy(X_train_np).float()\n",
    "y_train = torch.from_numpy(y_train_np).float()\n",
    "\n",
    "X_test = torch.from_numpy(X_test_np).float()\n",
    "y_test = torch.from_numpy(y_test_np).float()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.3333,  0.3333,  0.3333])\n"
     ]
    }
   ],
   "source": [
    "class LinearRF(nn.Module):\n",
    "    def __init__(self, num_features, num_dts):\n",
    "        super().__init__()\n",
    "        # Treat each timestep as independent feature!\n",
    "        out_size = 2\n",
    "        self.num_features = num_features\n",
    "        self.dt_weights = nn.Parameter(data=torch.ones(num_dts)/num_dts)#torch.rand(num_dts)/num_dts)\n",
    "        print(self.dt_weights)\n",
    "        \n",
    "        self.linear = nn.Linear(in_features=self.num_features,\n",
    "                                out_features=out_size)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Normalize dt_weights s.t. they are >= 0 and sum to 1\n",
    "        dt_weights = nn.functional.softmax(self.dt_weights, dim=0)\n",
    "    \n",
    "        # Shape: examples, num_dts, output (2)\n",
    "        x =  self.linear(x)\n",
    "\n",
    "        x = x.permute(1,2,0)\n",
    "        return (x * dt_weights).sum(dim=-1)\n",
    "    \n",
    "model = LinearRF(num_features=num_features, num_dts = num_dts).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4099, device='cuda:0')\n",
      "tensor(0.4607, device='cuda:0')\n",
      "tensor(0.4605, device='cuda:0')\n",
      "tensor(0.4605, device='cuda:0')\n",
      "0.4605485498905182\n"
     ]
    }
   ],
   "source": [
    "best_loss = torch.tensor(float('inf')).to(device)\n",
    "optimizer = optim.LBFGS(model.parameters())\n",
    "\n",
    "class L2MSELoss(nn.Module):\n",
    "    def __init__(self, lambda_reg, model):\n",
    "        super().__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, a, b):\n",
    "        loss = self.mse(a, b)\n",
    "        \n",
    "        loss_reg = 0.0\n",
    "        num_params = 0.0\n",
    "        for m in self.model.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                loss_reg += (m.weight**2).sum()\n",
    "                size = torch.tensor(m.weight.size()).prod()\n",
    "                num_params += size\n",
    "              \n",
    "        #loss_reg += (self.model.dt_weights**2).sum()\n",
    "        #num_params += self.model.dt_weights.shape[0]\n",
    "        \n",
    "        loss_reg = loss_reg.sqrt()/num_params.item()\n",
    "        return loss + self.lambda_reg * loss_reg\n",
    "        \n",
    "criterion = L2MSELoss(lambda_reg=0.1, model=model).to(device)\n",
    "\n",
    "while True:\n",
    "    def eval_model():\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X_train.to(device))\n",
    "        loss = criterion(out, y_train.to(device))\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    cur_loss = optimizer.step(closure=eval_model)\n",
    "    if best_loss - cur_loss > 10e-9:\n",
    "        best_loss = cur_loss\n",
    "        print(best_loss)\n",
    "    else:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16727211640464051,\n",
       " 0.10325354725643177,\n",
       " tensor([ 0.9015,  0.0695,  0.0290], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_train_hat = model(X_train.to(device)).cpu().data.numpy()\n",
    "y_test_hat = model(X_test.to(device)).cpu().data.numpy()\n",
    "\n",
    "r2_score(y_train_np, y_train_hat), r2_score(y_test_np, y_test_hat), nn.functional.softmax(model.dt_weights, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 2.3328, -0.2299, -1.1029], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dt_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.4243535038150776, pvalue=0.0) \n",
      " SpearmanrResult(correlation=0.4672948414083257, pvalue=0.0) \n",
      "\n",
      " SpearmanrResult(correlation=0.3273209706180686, pvalue=1.8279989868749893e-117) \n",
      " SpearmanrResult(correlation=0.3903689916786351, pvalue=1.8894353695115036e-170)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print(spearmanr(y_train_np[:,0], y_train_hat[:,0]),'\\n', \n",
    "      spearmanr(y_train_np[:,1], y_train_hat[:,1]),'\\n\\n',\n",
    "      spearmanr(y_test_np[:,0], y_test_hat[:,0]),'\\n', \n",
    "      spearmanr(y_test_np[:,1], y_test_hat[:,1]))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20786, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
