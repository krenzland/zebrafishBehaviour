{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dill as pickle\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')#\n",
    "from util import add_angles, angle_between, angled_vector, sub_angles\n",
    "from mdn_model.mixture_loss import *\n",
    "from mdn_model.models import *\n",
    "from data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_data(dir='../../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mdn networks\n",
    "covariance_type = 'diagonal'\n",
    "n_hidden = 64\n",
    "n_features = 192\n",
    "\n",
    "models = []\n",
    "\n",
    "checkpoint = torch.load('../../models/rnn_mdn.pt')\n",
    "encoder = RNNEncoder(n_features=n_features, n_hidden=n_hidden)\n",
    "decoder = MDNDecoder(n_hidden=n_hidden, n_components=5, covariance_type=covariance_type, covariance_reg=1e-6)\n",
    "model_rnn_mdn = ReceptiveFieldNN(encoder=encoder, decoder=decoder).to(device)\n",
    "model_rnn_mdn.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'rnn_mdn', 'model': model_rnn_mdn}]\n",
    "\n",
    "checkpoint = torch.load('../../models/mlp_mdn.pt')\n",
    "encoder = MLPEncoder(n_features=n_features, n_hidden=n_hidden)\n",
    "decoder = MDNDecoder(n_hidden=n_hidden, n_components=5, covariance_type=covariance_type, covariance_reg=1e-6)\n",
    "model_mlp_mdn = ReceptiveFieldNN(encoder=encoder, decoder=decoder).to(device)\n",
    "model_mlp_mdn.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'mlp_mdn', 'model': model_mlp_mdn}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\t rnn_mdn\n",
      "NLL-Train:\t1.6156128644943237\n",
      "NLL-Test:\t1.70588219165802\n",
      "MSE-Train:\t0.4538816809654236\n",
      "MSE-Test:\t0.3838675618171692\n",
      "\n",
      "\n",
      "Model:\t mlp_mdn\n",
      "NLL-Train:\t1.7126191854476929\n",
      "NLL-Test:\t1.631034255027771\n",
      "MSE-Train:\t0.4635099768638611\n",
      "MSE-Test:\t0.3836168646812439\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_mdn(model, data):\n",
    "    pi, _, mu = [out.detach().cpu().numpy() for out in model(data.to(device))]\n",
    "    return (np.stack((pi, pi), axis=-1) * mu).sum(axis=1)\n",
    "    \n",
    "def evaluate_mdn(model_name, model):\n",
    "    model.eval()\n",
    "    criterion = MixtureLoss().to(device)\n",
    "    nll_train = criterion(*model(X_train.to(device)), y_train.to(device))\n",
    "    nll_test = criterion(*model(X_test.to(device)), y_test.to(device))\n",
    "    \n",
    "    y_train_hat = predict_mdn(model, X_train)\n",
    "    y_test_hat = predict_mdn(model, X_test)\n",
    "\n",
    "    mse_train = mean_squared_error(y_true=y_train.numpy(),\n",
    "                                  y_pred=y_train_hat)\n",
    "    \n",
    "    mse_test = mean_squared_error(y_true=y_test.numpy(),\n",
    "                                  y_pred=y_test_hat)\n",
    "       \n",
    "    print(f\"Model:\\t {model_name}\",\n",
    "          f\"NLL-Train:\\t{nll_train}\",\n",
    "          f\"NLL-Test:\\t{nll_test}\",\n",
    "          f\"MSE-Train:\\t{mse_train}\",\n",
    "          f\"MSE-Test:\\t{mse_test}\",\n",
    "          \"\\n\",\n",
    "          sep='\\n')\n",
    "\n",
    "for model in models:\n",
    "    evaluate_mdn(**model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tstatic_mse\n",
      "Comment:\t[0.07749587 0.07123938 0.08565702 0.04881955 0.04296434 0.06331023\n",
      " 0.61051357]\n",
      "NLL-Train:\t2.0750389099121094\n",
      "NLL-Test:\t1.9075170755386353\n",
      "MSE-Train:\t0.4666251540184021\n",
      "MSE-Test:\t0.39072132110595703\n",
      "\n",
      "\n",
      "Model:\trnn_mse\n",
      "Comment:\t\n",
      "NLL-Train:\t2.036006212234497\n",
      "NLL-Test:\tinf\n",
      "MSE-Train:\t0.4487975835800171\n",
      "MSE-Test:\t0.39261770248413086\n",
      "\n",
      "\n",
      "Model:\tmlp_mse\n",
      "Comment:\t\n",
      "NLL-Train:\t2.0776877403259277\n",
      "NLL-Test:\t1.9028756618499756\n",
      "MSE-Train:\t0.4678916335105896\n",
      "MSE-Test:\t0.3884059190750122\n",
      "\n",
      "\n",
      "Model:\tridge_no_memory\n",
      "Comment:\t29.145192568009907\n",
      "NLL-Train:\t2.085383653640747\n",
      "NLL-Test:\t1.9033443927764893\n",
      "MSE-Train:\t0.4715184762116639\n",
      "MSE-Test:\t0.3880725189137647\n",
      "\n",
      "\n",
      "Model:\tridge_concatenate\n",
      "Comment:\t172.27429147699408\n",
      "NLL-Train:\t2.05780291557312\n",
      "NLL-Test:\tinf\n",
      "MSE-Train:\t0.45863390081963384\n",
      "MSE-Test:\t0.3849223177673447\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_nll_mean(gt, predictions, train_variance):\n",
    "    \"\"\"Computes the negative log likelihood from mean predictions.\n",
    "    Useful to estimate the nll for linear models\"\"\"\n",
    "    # Model output as mixture of one Gaussian with diagonal cov matrix.\n",
    "    criterion = MixtureLoss(covariance_type='diagonal')\n",
    "    # Mean is given by predictions.\n",
    "    mu_l = predictions.reshape(-1,1,2)\n",
    "    # Pi is one (only one component!)\n",
    "    pi_l = np.ones((predictions.shape[0],1))\n",
    "    \n",
    "    # Variance is same for each example (by homoscedasticity)\n",
    "    sigma_l = np.tile((train_variance)[:,None], predictions.shape[0]).T.reshape(-1,1,2)\n",
    "    return criterion(pi=torch.from_numpy(pi_l).float(),\n",
    "                     sigma=torch.from_numpy(sigma_l).float(),\n",
    "                     mu=torch.from_numpy(mu_l).float(),\n",
    "                     y=torch.from_numpy(gt).float())\n",
    "\n",
    "from train_linear import convert_data_concatenate, convert_data_no_memory\n",
    "X_train_conc = convert_data_concatenate(X_train.numpy())\n",
    "X_test_conc = convert_data_concatenate(X_test.numpy())\n",
    "\n",
    "X_train_no_memory = convert_data_no_memory(X_train.numpy())\n",
    "X_test_no_memory = convert_data_no_memory(X_test.numpy())\n",
    "\n",
    "def evaluate_mse(model_name, model):\n",
    "    if isinstance(model, nn.Module):\n",
    "        model.eval()\n",
    "        \n",
    "    nll_train = None\n",
    "    nll_test = None\n",
    "    \n",
    "    if 'conc' in model_name:\n",
    "        X_train_linear = X_train_conc\n",
    "        X_test_linear = X_test_conc\n",
    "    else:\n",
    "        X_train_linear = X_train_no_memory\n",
    "        X_test_linear = X_test_no_memory\n",
    "    \n",
    "    if 'mse' in model_name:\n",
    "        y_train_hat = model(X_train.to(device)).detach().cpu().numpy()\n",
    "        y_test_hat = model(X_test.to(device)).detach().cpu().numpy()\n",
    "    else:\n",
    "        y_train_hat = model.predict(X_train_linear)\n",
    "        y_test_hat = model.predict(X_test_linear)\n",
    "\n",
    "    train_variance = np.var(y_train.numpy() - y_train_hat, axis=0)\n",
    "    \n",
    "    nll_train = compute_nll_mean(gt=y_train.numpy(),\n",
    "                                predictions=y_train_hat,\n",
    "                                train_variance=train_variance)\n",
    "    nll_test = compute_nll_mean(gt=y_test.numpy(),\n",
    "                            predictions=y_test_hat,\n",
    "                            train_variance=train_variance)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_true=y_train.numpy(),\n",
    "                                  y_pred=y_train_hat)\n",
    "    \n",
    "    mse_test = mean_squared_error(y_true=y_test.numpy(),\n",
    "                                  y_pred=y_test_hat)\n",
    "    alpha = model.alpha_ if isinstance(model, RidgeCV) else \"\"\n",
    "    if isinstance(model, RidgeCV):\n",
    "        comment = model.alpha_\n",
    "    elif isinstance(model, StaticSpatialLinearEncoder):\n",
    "        comment = nn.functional.softmax(model.dt_weights, dim=0).cpu().detach().numpy()\n",
    "    else:\n",
    "        comment = \"\"\n",
    "        \n",
    "    print(f\"Model:\\t{model_name}\",\n",
    "          f\"Comment:\\t{comment}\",\n",
    "          f\"NLL-Train:\\t{nll_train}\",\n",
    "          f\"NLL-Test:\\t{nll_test}\",\n",
    "          f\"MSE-Train:\\t{mse_train}\",\n",
    "          f\"MSE-Test:\\t{mse_test}\",\n",
    "          \"\\n\",\n",
    "          sep='\\n')\n",
    "    \n",
    "models = []\n",
    "\n",
    "checkpoint = torch.load('../../models/static_mse.pt')\n",
    "model_static_mse = StaticSpatialLinearEncoder(n_features=n_features,\n",
    "                                             n_dts=X_train.shape[0]).to(device)\n",
    "model_static_mse.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'static_mse', 'model': model_static_mse}]\n",
    "\n",
    "checkpoint = torch.load('../../models/rnn_mse.pt')\n",
    "encoder = RNNEncoder(n_features=n_features, n_hidden=n_hidden)\n",
    "decoder = NormalDecoder(n_hidden=n_hidden)\n",
    "model_rnn_mse = ReceptiveFieldNN(encoder=encoder, decoder=decoder).to(device)\n",
    "model_rnn_mse.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'rnn_mse', 'model': model_rnn_mse}]\n",
    "\n",
    "checkpoint = torch.load('../../models/mlp_mse.pt')\n",
    "encoder = MLPEncoder(n_features=n_features, n_hidden=n_hidden)\n",
    "decoder = NormalDecoder(n_hidden=n_hidden)\n",
    "model_mlp_mse = ReceptiveFieldNN(encoder=encoder, decoder=decoder).to(device)\n",
    "model_mlp_mse.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'mlp_mse', 'model': model_mlp_mse}]\n",
    "\n",
    "with open('../../models/linear_no_memory.model', 'rb') as file:\n",
    "    linear_no_memory = pickle.load(file)\n",
    "with open('../../models/linear_concatenate.model', 'rb') as file:\n",
    "    linear_concatenate = pickle.load(file)   \n",
    "    \n",
    "models += [{'model_name': 'ridge_no_memory', 'model': linear_no_memory}]\n",
    "models += [{'model_name': 'ridge_concatenate', 'model': linear_concatenate}]\n",
    "\n",
    "for model in models:\n",
    "    evaluate_mse(**model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
