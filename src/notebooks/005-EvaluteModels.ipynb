{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dill as pickle\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')#\n",
    "from util import add_angles, angle_between, angled_vector, sub_angles\n",
    "from mdn_model.mixture_loss import *\n",
    "from mdn_model.models import *\n",
    "from data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_data(dir='../../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mdn networks\n",
    "covariance_type = 'diagonal'\n",
    "n_hidden = 64\n",
    "n_features = 192\n",
    "\n",
    "models = []\n",
    "\n",
    "checkpoint = torch.load('../../models/rnn_mdn.pt')\n",
    "encoder = RNNEncoder(n_features=n_features, n_hidden=n_hidden)\n",
    "decoder = MDNDecoder(n_hidden=n_hidden, n_components=5, covariance_type=covariance_type, covariance_reg=1e-6)\n",
    "model_rnn_mdn = ReceptiveFieldNN(encoder=encoder, decoder=decoder).to(device)\n",
    "model_rnn_mdn.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'rnn_mdn', 'model': model_rnn_mdn}]\n",
    "\n",
    "checkpoint = torch.load('../../models/mlp_mdn.pt')\n",
    "encoder = MLPEncoder(n_features=n_features, n_hidden=n_hidden)\n",
    "decoder = MDNDecoder(n_hidden=n_hidden, n_components=5, covariance_type=covariance_type, covariance_reg=1e-6)\n",
    "model_mlp_mdn = ReceptiveFieldNN(encoder=encoder, decoder=decoder).to(device)\n",
    "model_mlp_mdn.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'mlp_mdn', 'model': model_mlp_mdn}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\t rnn_mdn\n",
      "NLL-Train:\t1.4309556564481103\n",
      "NLL-Test:\t1.6875687837600708\n",
      "MSE-Train:\t0.43623560667037964\n",
      "MSE-Test:\t0.37120217084884644\n",
      "\n",
      "\n",
      "Model:\t mlp_mdn\n",
      "NLL-Train:\t1.6296065007633673\n",
      "NLL-Test:\t1.597421407699585\n",
      "MSE-Train:\t0.447751522064209\n",
      "MSE-Test:\t0.3727840185165405\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_mdn(model, data):\n",
    "    pi, _, mu = [out.detach().cpu().numpy() for out in model(data.to(device))]\n",
    "    return (np.stack((pi, pi), axis=-1) * mu).sum(axis=1)\n",
    "    \n",
    "def evaluate_mdn(model_name, model):\n",
    "    model.eval()\n",
    "    criterion = MixtureLoss().to(device)\n",
    "    nll_train = criterion(*[o.double() for o in model(X_train.to(device))], y_train.to(device).double())\n",
    "    nll_test = criterion(*model(X_test.to(device)), y_test.to(device))\n",
    "    \n",
    "    y_train_hat = predict_mdn(model, X_train)\n",
    "    y_test_hat = predict_mdn(model, X_test)\n",
    "\n",
    "    mse_train = mean_squared_error(y_true=y_train.numpy(),\n",
    "                                  y_pred=y_train_hat)\n",
    "    \n",
    "    mse_test = mean_squared_error(y_true=y_test.numpy(),\n",
    "                                  y_pred=y_test_hat)\n",
    "       \n",
    "    print(f\"Model:\\t {model_name}\",\n",
    "          f\"NLL-Train:\\t{nll_train}\",\n",
    "          f\"NLL-Test:\\t{nll_test}\",\n",
    "          f\"MSE-Train:\\t{mse_train}\",\n",
    "          f\"MSE-Test:\\t{mse_test}\",\n",
    "          \"\\n\",\n",
    "          sep='\\n')\n",
    "\n",
    "for model in models:\n",
    "    evaluate_mdn(**model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tridge_no_memory\n",
      "Comment:\t19.916480638308585\n",
      "NLL-Train:\t2.041607232524099\n",
      "NLL-Test:\t1.8683679000952478\n",
      "MSE-Train:\t0.45139711445044906\n",
      "MSE-Test:\t0.37579735507351114\n",
      "\n",
      "\n",
      "Model:\tridge_concatenate\n",
      "Comment:\t286.2153445389273\n",
      "NLL-Train:\t1.9986462498116737\n",
      "NLL-Test:\t1.8555734535565738\n",
      "MSE-Train:\t0.4323258718932058\n",
      "MSE-Test:\t0.37277552990758805\n",
      "\n",
      "\n",
      "Model:\tstatic_mse\n",
      "Comment:\t[0.04963709 0.05144349 0.05624986 0.06347179 0.07293913 0.07582849\n",
      " 0.1051606  0.52526957]\n",
      "NLL-Train:\t2.0417163697996616\n",
      "NLL-Test:\t1.8646876465140054\n",
      "MSE-Train:\t0.4513101279735565\n",
      "MSE-Test:\t0.37361612915992737\n",
      "\n",
      "\n",
      "Model:\tmlp_mse\n",
      "Comment:\t\n",
      "NLL-Train:\t2.0420709678157287\n",
      "NLL-Test:\t1.8664833758808064\n",
      "MSE-Train:\t0.4516063332557678\n",
      "MSE-Test:\t0.37489619851112366\n",
      "\n",
      "\n",
      "Model:\trnn_mse\n",
      "Comment:\t\n",
      "NLL-Train:\t1.9978073354843395\n",
      "NLL-Test:\t1.8648829612902957\n",
      "MSE-Train:\t0.4319530129432678\n",
      "MSE-Test:\t0.3767538070678711\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_nll_mean(gt, predictions, train_variance):\n",
    "    \"\"\"Computes the negative log likelihood from mean predictions.\n",
    "    Useful to estimate the nll for linear models\"\"\"\n",
    "    # Model output as mixture of one Gaussian with diagonal cov matrix.\n",
    "    criterion = MixtureLoss(covariance_type='diagonal')\n",
    "    # Mean is given by predictions.\n",
    "    mu_l = predictions.reshape(-1,1,2)\n",
    "    # Pi is one (only one component!)\n",
    "    pi_l = np.ones((predictions.shape[0],1))\n",
    "    \n",
    "    # Variance is same for each example (by homoscedasticity)\n",
    "    sigma_l = np.tile((train_variance)[:,None], predictions.shape[0]).T.reshape(-1,1,2)\n",
    "    return criterion(pi=torch.from_numpy(pi_l).double(),\n",
    "                     sigma=torch.from_numpy(sigma_l).double(),\n",
    "                     mu=torch.from_numpy(mu_l).double(),\n",
    "                     y=torch.from_numpy(gt).double())\n",
    "\n",
    "from train_linear import convert_data_concatenate, convert_data_no_memory\n",
    "X_train_conc = convert_data_concatenate(X_train.numpy())\n",
    "X_test_conc = convert_data_concatenate(X_test.numpy())\n",
    "\n",
    "X_train_no_memory = convert_data_no_memory(X_train.numpy())\n",
    "X_test_no_memory = convert_data_no_memory(X_test.numpy())\n",
    "\n",
    "def evaluate_mse(model_name, model):\n",
    "    if isinstance(model, nn.Module):\n",
    "        model.eval()\n",
    "        \n",
    "    nll_train = None\n",
    "    nll_test = None\n",
    "    \n",
    "    if 'conc' in model_name:\n",
    "        X_train_linear = X_train_conc\n",
    "        X_test_linear = X_test_conc\n",
    "    else:\n",
    "        X_train_linear = X_train_no_memory\n",
    "        X_test_linear = X_test_no_memory\n",
    "    \n",
    "    if 'mse' in model_name:\n",
    "        y_train_hat = model(X_train.to(device)).detach().cpu().numpy()\n",
    "        y_test_hat = model(X_test.to(device)).detach().cpu().numpy()\n",
    "    else:\n",
    "        y_train_hat = model.predict(X_train_linear)\n",
    "        y_test_hat = model.predict(X_test_linear)\n",
    "\n",
    "    train_variance = np.var(y_train.numpy() - y_train_hat, axis=0)\n",
    "    \n",
    "    nll_train = compute_nll_mean(gt=y_train.numpy(),\n",
    "                                predictions=y_train_hat,\n",
    "                                train_variance=train_variance)\n",
    "    nll_test = compute_nll_mean(gt=y_test.numpy(),\n",
    "                            predictions=y_test_hat,\n",
    "                            train_variance=train_variance)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_true=y_train.numpy(),\n",
    "                                  y_pred=y_train_hat)\n",
    "    \n",
    "    mse_test = mean_squared_error(y_true=y_test.numpy(),\n",
    "                                  y_pred=y_test_hat)\n",
    "    alpha = model.alpha_ if isinstance(model, RidgeCV) else \"\"\n",
    "    if isinstance(model, RidgeCV):\n",
    "        comment = model.alpha_\n",
    "    elif isinstance(model, StaticSpatialLinearEncoder):\n",
    "        comment = nn.functional.softmax(model.dt_weights, dim=0).cpu().detach().numpy()\n",
    "    else:\n",
    "        comment = \"\"\n",
    "        \n",
    "    print(f\"Model:\\t{model_name}\",\n",
    "          f\"Comment:\\t{comment}\",\n",
    "          f\"NLL-Train:\\t{nll_train}\",\n",
    "          f\"NLL-Test:\\t{nll_test}\",\n",
    "          f\"MSE-Train:\\t{mse_train}\",\n",
    "          f\"MSE-Test:\\t{mse_test}\",\n",
    "          \"\\n\",\n",
    "          sep='\\n')\n",
    "    \n",
    "models = []\n",
    "\n",
    "with open('../../models/linear_no_memory.model', 'rb') as file:\n",
    "    linear_no_memory = pickle.load(file)\n",
    "with open('../../models/linear_concatenate.model', 'rb') as file:\n",
    "    linear_concatenate = pickle.load(file)   \n",
    "    \n",
    "models += [{'model_name': 'ridge_no_memory', 'model': linear_no_memory}]\n",
    "models += [{'model_name': 'ridge_concatenate', 'model': linear_concatenate}]\n",
    "\n",
    "checkpoint = torch.load('../../models/static_mse.pt')\n",
    "model_static_mse = StaticSpatialLinearEncoder(n_features=n_features,\n",
    "                                             n_dts=X_train.shape[0]).to(device)\n",
    "model_static_mse.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'static_mse', 'model': model_static_mse}]\n",
    "\n",
    "checkpoint = torch.load('../../models/mlp_mse.pt')\n",
    "encoder = MLPEncoder(n_features=n_features, n_hidden=n_hidden)\n",
    "decoder = NormalDecoder(n_hidden=n_hidden)\n",
    "model_mlp_mse = ReceptiveFieldNN(encoder=encoder, decoder=decoder).to(device)\n",
    "model_mlp_mse.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'mlp_mse', 'model': model_mlp_mse}]\n",
    "\n",
    "checkpoint = torch.load('../../models/rnn_mse.pt')\n",
    "encoder = RNNEncoder(n_features=n_features, n_hidden=n_hidden)\n",
    "decoder = NormalDecoder(n_hidden=n_hidden)\n",
    "model_rnn_mse = ReceptiveFieldNN(encoder=encoder, decoder=decoder).to(device)\n",
    "model_rnn_mse.load_state_dict(checkpoint['model'])\n",
    "models += [{'model_name': 'rnn_mse', 'model': model_rnn_mse}]\n",
    "\n",
    "for model in models:\n",
    "    evaluate_mse(**model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55788696 0.42263234\n",
      "[0.5656871  0.55008703]\n",
      "tensor(2.2542, dtype=torch.float64) tensor(2.0100, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_mean = y_train.mean(dim=0).repeat(y_train.shape[0],1).numpy()\n",
    "y_pred_test_mean = y_train.mean(dim=0).repeat(y_test.shape[0],1).numpy()\n",
    "print(mean_squared_error(y_train.numpy(), y_pred_train_mean),\n",
    "mean_squared_error(y_test.numpy(), y_pred_test_mean))\n",
    "\n",
    "train_variance_mean = np.var(y_train.numpy() - y_pred_train_mean, axis=0)\n",
    "print(train_variance_mean)\n",
    "\n",
    "nll_mean_train = compute_nll_mean(gt=y_train.numpy(),\n",
    "                 predictions=y_pred_train_mean,\n",
    "                 train_variance=train_variance_mean)\n",
    "\n",
    "nll_mean_test = compute_nll_mean(gt=y_test.numpy(),\n",
    "                 predictions=y_pred_test_mean,\n",
    "                 train_variance=train_variance_mean)\n",
    "print(nll_mean_train, nll_mean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.65718094e-01, -4.63753541e-05],\n",
       "       [-4.63753541e-05,  5.50117386e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(y_train.numpy() - y_pred_train_mean, rowvar=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
